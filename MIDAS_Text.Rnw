\documentclass[a4paper, 14pt]{extarticle}


\usepackage{etex} % расширение классического tex
\usepackage{cmap} % для поиска русских слов в pdf
\usepackage{verbatim} % для многострочных комментариев
\usepackage{makeidx} % для создания предметных указателей


%\usepackage[T2A]{fontenc}
%\usepackage[utf8]{inputenc} % задание utf8 кодировки исходного tex файла
%\usepackage[russian, british]{babel} % выбор языка для документа


\usepackage{fontspec}
\usepackage{polyglossia}

\setmainlanguage{russian}
\setotherlanguages{english}

% download "Linux Libertine" fonts:
% http://www.linuxlibertine.org/index.php?id=91&L=1
\setmainfont{Cambria}

% or Helvetica, Arial, Cambria
% why do we need \newfontfamily:
% http://tex.stackexchange.com/questions/91507/
\newfontfamily{\cyrillicfonttt}{Courier New}

\usepackage{tabularx} % таблички растягиавать 
\usepackage{tabulary}
\usepackage{setspace}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{mathrsfs} % rsfs
%\usepackage{dsfont} % doublestroke
\usepackage{array,multicol,multirow,bigstrut} % texlive-multirow
\usepackage{indentfirst} % установка отступа в первом абзаце главы

\usepackage{bm}
\usepackage{bbm} % шрифт с двойными буквами
\usepackage[perpage]{footmisc}
\usepackage{dcolumn} % центрирование по разделителю для apsrtable

% создание гиперссылок в pdf
\usepackage[unicode,colorlinks=true,urlcolor=blue,hyperindex,breaklinks]{hyperref} 

% свешиваем пунктуацию 
% теперь знаки пунктуации могут вылезать за правую границу текста, при этом текст выглядит ровнее
\usepackage{microtype}

\usepackage{textcomp} % Чтобы в формулах можно было русские буквы писать через \text{}
\hyphenation{ }       % Правила переноса  слов
\emergencystretch=2em
\frenchspacing        % пробелы после знаков припенания не увеличиваются

\usepackage[paper=a4paper,top=20mm, bottom=20mm,left=25mm,right=15mm,includefoot]{geometry} % размер листа бумаги
%\usepackage{xcolor}

%\usepackage[pdftex]{graphicx} % для вставки графики 
\usepackage{float,longtable}
\usepackage{soulutf8}
\usepackage{enumitem} % дополнительные плюшки для списков
\usepackage{mathtools}
%\usepackage{embedfile} % Чтобы код LaTeXа включился как приложение в PDF-файл
\usepackage{booktabs} % более красивые таблицы
\setstretch{1.5}                          % Межстрочный интервал
\flushbottom                            % Эта команда заставляет LaTeX чуть растягивать строки, чтобы получить идеально прямоугольную страницу
\righthyphenmin=2       % Разрешение переноса двух и более символов
\pagestyle{plain}       % Нумерация страниц снизу по центру.
\widowpenalty=3000% одна строка абзаца на этой странице, остальное --- на следующей
\clubpenalty=900000         %одинокая строка в начале страницы
\setlength{\parindent}{2em}           % Красная строка.
\setlength{\topsep}{0pt}


%%%%%%%% Это окружение, которое выравнивает по центру без отступа, как у простого center
\newenvironment{center*}{%
  \setlength\topsep{0pt}
  \setlength\parskip{0pt}
  \begin{center}
}{
  \end{center}
}

\begin{document}
<<echo=FALSE, warning=FALSE, message=FALSE, include=FALSE>>=
library("knitr")
Sys.setlocale(locale = "C")
opts_chunk$set(message=FALSE, warning=FALSE,
                strip.white = FALSE, 
                tidy.opts=list(width.cutoff=60),
                dev = "cairo_pdf", 
                fig.align = "center", 
                fig.height=5, 
                fig.width=7)
#pdf.options(encoding = 'UTF8')
Sys.setlocale("LC_CTYPE", "russian")
knit_theme$set("moe")



@

<<echo=FALSE, warning=FALSE, message=FALSE>>=
library("dplyr")
library("formatR")
library("xtable")
#library("psych")
library("ggplot2")
#library("forecast")
#library("xts")
#library("zoo")
library("reshape2")
#library("devtools")
library("sophisthse")
#library("car")
#library("lmtest")
#library("sjPlot")
#library("memisc")
library("midasr")
@


 

\begin{titlepage}
  \begin{center}
\large
Национальный исследовательский университет \\
"ВЫСШАЯ ШКОЛА ЭКОНОМИКИ"\\
\vspace{0.25cm}
Факультет экономических наук
\vfill
    
\textsc{Курсовая работа}\\[5mm]
{\textbf{\Large Применение моделей MIDAS к Российским макроэкономическим данным}\\[2mm]}
\bigskip   
\end{center}
\vfill


\newbox{\lbox} \savebox{\lbox}{\hbox{Демешев Борис Борисович}} \newlength{\maxl} \setlength{\maxl}{\wd\lbox} \hfill\parbox{10cm}{ \hspace*{5cm}\hspace*{-5cm}Выполнила:\hfill\hbox to\maxl{Кузина Анна, БЭК132\hfill}\\ \hspace*{5cm}\hspace*{-5cm}Преподаватель:\hfill\hbox to\maxl{Демешев Борис Борисович}\\  } 

\vfill
\vfill


\begin{center}
  Москва\\ 2016 г.
\end{center}

\end{titlepage}


%%%%%%%%%%    Оглавление    %%%%%%%%%


\tableofcontents
\newpage


%%%%%%%%%%    Введение    %%%%%%%%%


\section{Введение}
Большинство моделей прогнозирования подразумевает, что используемые временные ряды имеют одинаковую частоту наблюдений. 
Однако, на практике данные по различным макроэкономическим или финансовым показателям собираются с разной частотой. 
Большинство макроэкономических показателей публикуются с частотой в квартал, а реже - в год. 
Так, данные по ВВП становятся доступны нам с максимальной частотой равной одному кварталу.
В то же время, из экономической теории известно, что такие макроэкономические показатели как ВВП или экспорт могут быть подвержены влиянию со стороны более "высокочастотных" переменных, таких как безработица, ставки процента или валютный курс. 

Одним из решений проблемы разночастотности данных является агрегирование низкочастотных данных, однако, оно может отрицательно сказаться на качестве полученных таким образом прогнозов, так как ведет к потере части информации о той или иной переменной.
Более того, высокочастотные данные на практике появляются в открытом доступе гораздо раньше низкочастотных за тот же период: данные по безработице за первые три месяца года могут быть доступны, в то время как ВВП первого квартала еще не опубликован.
В результате, появляется необходимость прогнозировать не только будущий, но текущий ВВП (now-casting), используя все доступные данные по высокочастотным переменным.

В основе данной работы лежат модели MIDAS(Mixed Data Sampling regression), предлагающие достаточно эффективный способ борьбы с проблемой разночастотности, и показавшие хорошие результаты при прогнозировании различных, в том числе и макроэкономических, данных. Помимо описания принципа работы моделей MIDAS большое внимание в работе будет уделено пакету \texttt{midasr} для \texttt{R}, предоставляющему широкие возможности для построения моделей с использованием разночастотных данных. Практическая часть работы включает в себя прогнозирование различных макроэкономических показателей с использованием MIDAS на российских данных, а также сравнение полученных результатов с прогнозами более простых моделей, таких как модель без ограничений (Step weighting), модель с агрегированными данными (Time Averaging), ARIMA, AR.

Основные цели работы заключаются в изучении базовых спецификаций моделей MIDAS, способах их реализации в \texttt{R}, а также в сравнении их по прогнозной силе с другими, более распространенными на данный момент моделями для прогнозирования.  

\newpage


%%%%%%%%%%    Основная часть    %%%%%%%%%

\section{Теоретическая часть}
\subsection{Неограниченная и агрегированная модели}
В моделях MIDAS предполагается, что исследователь строит регрессию низкочастотного ряда $Y_t$ на лаги высокочастотных данных $X_t$ (объясняющие данные могут состоять из одного или нескольких высокочастотных рядов). В более обобщенном виде в регрессию также включены лаги самого низкочастотного ряда.

%%%%%%%%%% Step weigtning %%%%%%%%%%%%%%%%%%%%%%%

Запишем уравнение регрессии в общем виде, используя $p$ лагов ($L$) низкочастотного ряда, а также $j_{max} = m \times k$ лагов ($L_{HF}$) высокочастотного, $m$ - количество высокочастотных наблюдений X за один низкочастотный период Y, $k$ - количество "длинных" лагов для X. В рамках данной работы подобную спецификацию модели можно назвать неограниченной, так как нет никаких дополнительных условий, ограничивающих значения, которые могут принимать коэффициенты.
\begin{equation}
\label{unrestricted_one}
Y_t = \gamma + \sum_{i=1}^{p} \alpha_i L^i Y_t + \sum_{j=0}^{m \times k}\beta_{j} L_{HF}^{j} X_{t} +\epsilon_t
\end{equation}
Если же в модели используется больше одной объясняющей переменной, то есть N высокочастотных рядов, неограниченная модель \eqref{unrestricted_one} приобретает более громоздкий вид:
\begin{equation}
\label{unrestricted_main}
Y_t = \gamma + \sum_{i=1}^{p} \alpha_i L^i Y_t + \sum_{n=1}^N \sum_{j=0}^{m \times k}\beta_{n}^{(j)} L_{HF}^{j} X_{t,n} +\epsilon_t
\end{equation}
Такая неограниченная модель, которую в литературе также называют Step Weighting [1], предполагает построение регрессии и оценку всех коэффициентов методом наименьших квадратов. Однако, количество коэффициентов, которое необходимо оценить, невероятно велико. Если быть точным, оно составляет $1+p+N\cdot j_{max}$. Для примера, если мы строим регрессию ВВП (с ежегодными данными) на уровень безработицы и объем производства нефти (ежемесячные наблюдения) на основании данных последних пяти лет (5 низкочастотных лагов), то мы получим $1+5+2\cdot 5 \cdot 12=126$ коэффициентов. Основная проблема, которая особенно актуальна для Российских исследований - недостаточное количество данных, чтобы получить оценки коэффициентов в данном случае.


%%%%%%%%%%%%%%%%%%%%% Time Av %%%%%%%%%%%%%%%%%%%%%%%
Наиболее простой способ сокращения числа коэффициентов в модели --- агрегирование высокочастотных данных, такие модели еще называют Time Averaging[1]. То есть можно просто взять среднее значение безработицы за 12 месяцев и получить ее годовое значение. Далее можно строить обычную неограниченную модель \eqref{unrestricted_main}, но уже для данных одинаковой частоты. 

\begin{equation}
\overline{X}_{t} = \frac 1m \sum_{i=1}^{m}X_i \nonumber
\end{equation}

\begin{equation}
\label{time_av}
Y_t = \gamma + \sum_{i=1}^{p} \alpha_i L^i Y_t + \sum_{n=1}^N \sum_{j=0}^{k}\beta_{n}^{(j)} L_{HF}^{j} \overline{X}_{t,n} +\epsilon_t
\end{equation}

В результате, количество коэффициентов может значительно сократиться. Если вернуться к примеру, рассмотренному выше, в аналогичной модели после агрегирования мы получим уже $1+5+2\cdot5 = 16$ коэффициентов, что на 110 оцениваемых параметров меньше, чем было изначально. Однако, нельзя гарантировать что каждое значение высокочастотного параметра имеет одинаковое влияние на зависимую переменную (а именно это и предполагается, когда мы усредняем значения за период). А значит, в результате подобного способа борьбы с разночастотностью мы теряем часть доступной нам информации, что может отрицательно сказаться на качестве получаемых прогнозов.


%%%%%%%%%%%%%%%%% MIDAS %%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Mixed data sampling regression}
В Ghysels, Santa-Clara, and Valkanov (2004)[3] впервые были описаны модели MIDAS, в которых подразумевается наличие определенной функциональной связи между коэффициентами регрессии, и, как следствие, значительно снижается количество параметров, которые необходимо оценить.
 В Ghysels, Sinko, and Valkanov (2007)[6] MIDAS модели показали отличные результаты при прогнозировании макроэкономических показателей. В этой же работе было представлено расширение моделей MIDAS, включающее в себя авторегрессионную динамику. В общем виде модели MIDAS подразумевают модификацию неограниченной модели \eqref{unrestricted_main}, которая теперь имеет следующий вид:
\begin{equation}
\label{restricted}
Y_t = \gamma + \sum_{i=1}^{p} \alpha_i L^i Y_t + \sum_{n=1}^N \beta_n B(L_{HF} , \theta_n) X_{t,n} +\epsilon_t,
\end{equation}
где $B(L_{HF} , \theta_n) = \sum\limits_{j=0}^{j_{max}}\Phi(\theta_n,k)L_{HF}^{j/m}$ --- многочлен, определяющий веса лагов высокочастотных наблюдений в модели.

При введении таких ограничений в модель количество коэффициентов значительно снижается. Так как используемые функции не являются линейными, оценки коэффициентов могут быть получены с использованием нелинейного метода наименьших квадратов (NLS). 

Получив оценки коэффициентов, мы можем строить прогноз для зависимой переменной. Пусть $T_y$ - индекс последнего доступного наблюдения низкочастотного ряда, а $T_x$ - последнего доступного наблюдения для $X$.  Оценка значения зависимой переменной через $h$ периодов может быть найдена следующим образом:

\begin{equation}
\label{forecast}
Y_{T_y+h} = \widehat{\gamma} + \sum_{i=1}^{p} \widehat{\alpha }_iL^i Y_{T_y} +  \widehat{\beta}B(L_{HF} , \widehat{\theta}_n) X_{T_x} 
\end{equation}

Из уравнения \eqref{forecast} можно сделать несколько важных выводов о специфике процесса прогнозирования с использованием моделей MIDAS. 
\begin{itemize}
\item Во-первых, прогноз зависит от выбранного горизонта. 
\end{itemize}

Так, если мы прогнозируем на 1 период вперед, необходимо учитывать это уже на этапе оценки коэффициентов, не включая в модель последние $m$ наблюдений низкочастотного ряда, которые будут использованы исключительно при построении самого прогноза. 
\begin{itemize}
\item Во-вторых, помимо того, что $m\cdot T_y$ может быть не равно $T_x$ (обычно низкочастотные данные публикуются позже высокочастотных), разница между двумя этими значениями может изменяться со временем. 
\end{itemize}

Например, мы хотим спрогнозировать ВВП страны в зависимости от уровня безработицы в ней. Находясь в апреле 2016 года, мы обладаем данными о квартальном ВВП вплоть до $Q_4 2015$ и ежемесячными данными по безработице до \textit{февраля 2016}. Таким образом, мы можем, используя имеющуюся информацию, прогнозировать ВВП \textbf{1 квартала} 2016 года. Через месяц, в мае, доступная информация о ВВП никак не изменится, однако, опубликуют данные по безработице в \textit{марте}, а значит, можно обновить прогноз по ВВП, используя новую информацию.


%%%%%%%%%%%%%%%%%%% про ограничения %%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Функции ограничений}
Для полной спецификации модели осталось определить вид функции $B(\theta_n,k)$. 
Она может принимать различные функциональные формы, которые в общем виде выглядят следующим образом:

\begin{equation}
\Phi(\theta_n,k)=\frac{f(\theta_n,k)}{\sum\limits_{j=0}^{j_{max}} f(\theta_n, j)}
\end{equation}
В данной работе используются ограничения, впервые изложенные в работах  Ghysels et al. (2005, 2007) [4,6]
Первая функция получила название \textbf{Экспоненциальный лаг Алмон} (Exponential Almon Lag):

\begin{equation}
\label{Almon}
f(\theta_n,k) = exp(\theta_n^{(1)} k+...+\theta_n^{(q)} k^q)
\end{equation}

<<echo = FALSE>>=
lags_exp <- seq(1,252, 1)
len_exp <- length(lags_exp)

exp_func <- function(k, theta_1, theta_2){
  f = exp(theta_1*k+theta_2*(k^2))
  return(f)
}

restriction_exp <- function(k, theta_1, theta_2){
  inter = 0
  for (i in 1:len_exp){
    inter = inter + exp_func(lags_exp[i], theta_1, theta_2)
  }
  return(exp_func(k, theta_1, theta_2)/inter)
}

weights_exp <- data.frame(lags_exp = lags_exp, weight_1 = rep(NA, len_exp),
                      weight_2 = rep(NA, len_exp),
                      weight_3 = rep(NA, len_exp),
                      weight_4 = rep(NA, len_exp))
for (i in 1:len_exp){
  weights_exp[i,2] <- restriction_exp(lags_exp[i], 0.0007,-0.0004)
  weights_exp[i,3] <- restriction_exp(lags_exp[i], 0.006,-0.0008)
  weights_exp[i,4] <- restriction_exp(lags_exp[i], 0.03,-0.0007)
  weights_exp[i,5] <- restriction_exp(lags_exp[i], 0.0001,-0.0001)
}

weight_long_exp <- melt(weights_exp, value.name = "weight", 
                    measure.vars = c("weight_1","weight_2",
                                     "weight_3","weight_4"))

@

<<echo=FALSE>>=
qplot(data = weight_long_exp, x = lags_exp, y = weight,color = variable, geom = "line") + 
  theme(legend.position = c(0.86, 0.74), 
        legend.key.size = unit(1.5,"cm"),
        text = element_text(size = 14))+
  labs(list(title = "Рисунок 1. Экспоненциальный лаг", 
            x = "Лаги", y = "Веса наблюдений "))+
  scale_colour_discrete(name="",
                        breaks=c("weight_1", "weight_2", "weight_3","weight_4"),
                        labels=c("0.0007,-0.0004","0.006,-0.0008","0.03,-0.0007", "0.0001,-0.0001"))
@


Основным достоинством данной функции можно считать ее способность принимать разнообразные формы несмотря на небольшое количество параметров, которые за это отвечают. Во многих работах, в частности впервые в Ghysels, Santa-Clara, and Valkanov (2005), используется частный случай данной функции с двумя коэффициентами (при $q = 2$). Как видно из Рисунка 1\footnote{Приложение 1}, выбирая различные значения всего двух параметров, мы можем получать совершенно разные формы зависимостей: как убывающие с различными скоростями, так и "горбатые". Если же требуется, чтобы все коэффициенты имели равный вес, достаточно выбрать значения параметров $ \theta_1=\theta_2=0$. Этот случай не изображен на рисунке, однако это можно увидеть из уравнения \eqref{Almon}

Вторая спецификация функции ограничений также зависит только от двух параметров ($\theta_n = (\theta_n^{(1)}, \theta_n^{(2)})$) и названа авторами \textbf{Бета Лаг} (Beta Lag), так как основана на бета-функции.

\begin{align}
\label{Beta}
f(\theta_n^{(1)}, \theta_n^{(2)},a) &= \frac{a^{\theta_n^{(1)}-1}(1-a)^{\theta_n^{(2)}-1}\Gamma(\theta_n^{(1)}+\theta_n^{(2)})}{\Gamma(\theta_n^{(1)})\Gamma(\theta_n^{(2)})}\\
\Gamma(b) &= \int_{0}^{\infty} e^{-x}x^{b-1} dx \nonumber\\
a &= \frac{k}{j_{max}} \nonumber
\end{align}


<<echo = FALSE>>=
lags <- seq(1,84, 1)
len <- length(lags)

beta_func <- function(k, theta_1, theta_2){
  a = k/len
  f = (a^(theta_1-1)*(1-a)^(theta_2-1))/beta(theta_1, theta_2)
  return(f)
}

restriction <- function(k, theta_1, theta_2){
  inter = 0
  for (i in 1:len){
    inter = inter + beta_func(lags[i], theta_1, theta_2)
  }
  return(beta_func(k, theta_1, theta_2)/inter)
}

weights <- data.frame(lags = lags, weight_1 = rep(NA, len),
                      weight_2 = rep(NA, len),weight_3 = rep(NA, len),
                      weight_4 = rep(NA, len))
for (i in 1:len){
  weights[i,2] <- restriction(lags[i], 1,30)
  weights[i,3] <- restriction(lags[i], 4,9)
  weights[i,4] <- restriction(lags[i], 1.5,3)
  weights[i,5] <- restriction(lags[i], 2,18)
}

weight_long <- melt(weights, value.name = "weight", 
                    measure.vars = c("weight_1","weight_2","weight_3","weight_4"))

@

<<echo = FALSE, fig.height=5, fig.width=7>>=
qplot(data = weight_long, x = lags, y = weight,color = variable, geom = "line") + 
  theme(legend.position = c(0.91, 0.74), 
        legend.key.size = unit(1.5,"cm"),
        text = element_text(size = 14))+
  labs(list(title = "Рисунок 2. Бета-функция", 
            x = "Лаги", y = "Веса наблюдений "))+
  scale_colour_discrete(name="",
                        breaks=c("weight_1", "weight_2", "weight_3","weight_4"),
                        labels=c("1; 30","4; 9","1.5; 3", "2; 18"))+
  ylim(0,0.15)

@

Также, как и в предыдущей спецификации ограничений, мы можем регулировать форму функции, изменяя значения параметров $\theta$. Рисунок 2\footnote[2]{Приложение 1} демонстрирует несколько примеров того, какие формы может принимать данная функция ограничений. Здесь также возможен случай, когда все лаги имеют одинаковый вес. Как можно увидеть из уравнения \eqref{Beta}, ему соответствуют значения параметров $\theta_1=\theta_2=1$.

Данные функции обладают несколькими важными свойствами. Они всегда положительны и в сумме дают единицу, что позволяет использовать их именно в качестве весов для лагов высокочастотного ряда. Также можно заметить, что обе функции с определенного момента убывают и стремятся к 0 на бесконечности. Скорость убывания функции по сути определяет количество используемых лагов. Быстрое убывание соответствует небольшому количеству лагов, плавное --- наоборот большому.

%%%%%%%%%%%%%%%%%%%%  MIDAS_R %%%%%%%%%%%%%%%%%
\newpage
\section{MIDAS в R}

%%%%%%%%%%%%%%%% Данные %%%%%%%%%%%%%%%%%%%%%%

\subsection{Первичная обработка данных}
Для прогнозирования разночастотных данных с помощью моделей MIDAS можно использовать пакет \textit{midasr}, в котором есть все необходимые для этого функции. Рассмотрим принцип их работы на примере. Возьмем данные о ежемесячной безработице с сайта \href{http://sophist.hse.ru/}{Sophist.hse.ru}, а также квартальный ВВП с сайта \href{http://www.gks.ru/}{Росстат}.

<<>>=
gdp <- read.csv("gdp.csv") %>% tail(-2)
unemp <- read.csv("unemp.csv")
@

Для начала, разделим имеющиеся данные на тренировочную и тестовую выборки, чтобы иметь возможность оценить качество полученных прогнозов. В тестовую выборку войдут данные по ВВП за 2014 и 2015 года (то есть 8 квартальных наблюдений). А также обрежем данные по безработице, чтобы они соответствовали тренировочной выборке по ВВП. У нас должно быть ровно в 3 раза больше наблюдений по безработице, чем по ВВП, так как мы наблюдаем ее в 3 раза чаще.

<<>>=
gdp_full <- gdp[,2]
unemp_full <- unemp[, 2]
tr_gdp <- gdp_full %>% head(-8) %>% tail(-1)
tr_unemp <- unemp_full %>%
          head(which(unemp[, 1] == "dec 2013")) %>% 
          tail(-1)
trend <- 1:length(tr_gdp)
@


Для того, чтобы оценить модель, необходимо привести все данные к матричному виду. Так, если предполагаем, что $Y$ зависит от трех своих предыдущих значений, а также от 6 лагов высокочастотного ряда, модель в матричной форме принимает следующий вид:

\begin{equation}
\label{matrix}
\begin{bmatrix} 
Y_3  \\ 
Y_4  \\ 
\vdots\\
Y_{T_y}
 \end{bmatrix}
 =\gamma +
 \begin{bmatrix} 
Y_2&Y_1  \\ 
Y_3&Y_2  \\ 
\vdots & \vdots\\
Y_{T_y-1} & Y_{T_y-2}
 \end{bmatrix}
 \alpha +
 \begin{bmatrix} 
X_6 &  \dots & X_1 \\ 
X_9 &  \dots & X_4 \\ 
\vdots  & &\vdots\\
X_{T_x}&   \dots & X_{T_x-5} \\ 
 \end{bmatrix}
 \cdot
 \begin{bmatrix} 
\beta_1  \\ 
\beta_2 \\ 
\vdots\\
\beta_6
 \end{bmatrix}
 +
 \begin{bmatrix} 
\varepsilon_3  \\ 
\varepsilon_4  \\ 
\vdots\\
\varepsilon_{T_y}
 \end{bmatrix}
\end{equation}
 
 Для того,чтобы перевести имеющийся вектор данных в матричный вид, можно воспользоваться функцией \texttt{mls(x, k,m)}, которая из вектора x делает матрицу размерности $\dfrac{dim x}{m} \times dim k$. Ее можно использовать для перевода высокочастотной переменной x в $dim k$ низкочастотных переменных, по $dim x / m$ наблюдений в каждой. Рассмотрим простой пример, в котором вектор из 12 высокочастотных наблюдений переведем в 3 низкосатотные переменные. 
 
<<>>=
x <- 1:12
mls(x, 1:3, 3)
@

Мы получили 3 низкочастотные переменные, каждая из которых состоит из 4 наблюдений. $k$ показывает, какие именно лаги исходной переменной мы хотим включить в матрицу. В примере мы начинаем с первого лага, поэтому самое последнее наблюдение не было включено.

В нашем случае, если мы хотим, чтобы в модель входило 6 лагов вектора безработицы, включая самое последнее наблюдение, и два предыдущих значения ВВП, то надо построить следующие матрицы:

<<>>=
unemp_matr <- mls(tr_unemp, 0:5, 3)
gdp_matr <- mls(tr_gdp, 1:2,1)
@

Прежде чем строить регрессию, проверим наличие связи между квартальным ВВП и средней безработицей за квартал, изобразив их на графике. 
<<>>=
qplot(tr_gdp, rowMeans(mls(tr_unemp, 0:4, 3)))+
  labs(list(
    title = "Рисунок 3. Зависимость между ВВП и безработицей", 
    x = "Индекс реального ВВП, % от Q1 1995", 
    y = "Средний уровень безработицы, %"))
@

Мы можем видеть на графике, что квартальный ВВП отрицательно зависит от среднего уровня безработицы за этот же период. 

%%%%%%%%%%%% Выбор ограничений и лагов %%%%%%%%%%%%%%%%%%%%%

\subsection{Оценка моделей: выбор ограничений и числа лагов}

Мы уже определии, что существует отрицательная зависимость между ВВП и бехработицей, но для прогнозирования этого не достаточно. Для того, чтобы построить модель с разночастотными данными, удобно использовать функцию \texttt{midas\_r()}. Начнем с модели без ограничений, включив в регрессию 4 и 8 лагов низкочастотного и высокочастотного рядов соответственно. Совершенно аналогичный результат мы получим, если будем использовать обычный МНК (\texttt{lm}), так как никаких ограничений на коэффициенты мы не накладываем.
<<results= 'asis'>>=
model <- midas_r(tr_gdp ~ trend + mls(tr_gdp,1:4 ,1) + 
                   mls(tr_unemp, 0:7,3), start = NULL)
tab1 <- xtable(summary(model)$coefficients, 
       caption="Коэффициенты в неограниченной модели")
align(tab1) <- "XXXXX"
print(tab1,tabular.environment = "tabularx", 
      width = "\\textwidth") 
@

В данном случае мы можем легко интерпретировать коэффициенты, а также понять, как именно выглядит оцененная зависимость. Так, наблюдается значимая полодительная связь между текущим и предыдущим значением ВВП. А вот коэффициенты перед лагами безработицы оказались значимы только для удаленных ее значений (начиная с 5 лага) и не все имеют отрицательный знак. 
\begin{equation}\begin{split}
\widehat{GDP_t} =  39.148 + & 0.256 t + 0.967 GDP_{t-1} - 0.126 GDP_{t-2} - 0.152 GDP_{t-3} + \\
 + &0.01 GDP_{t-4} -  2.221 unemp_{3t} +1.144 unemp_{3t-1} - \\
 + & 0.279 unemp_{3t-2} - 1.44 unemp_{3t-3} + 5.545 unemp_{3t-4} -\\
 - & 4.042 unemp_{3t-5}- 05.403 unemp_{3t-6} + 5.191 unemp_{3t-7}  
\end{split}\end{equation}

Мы получили достаточно громоздкую формулу с большим количество коэффициентов. Однако, можно значительно сократить их число, введя функцию, которая будет ограничивать коэффициенты перед высокочастотной переменной. Мы по-прежнему будем использовать 8 лагов безработицы, однако, используя команду \texttt{nealmon}, ограничим их функцией экспоненциального лага \eqref{Almon} и, таким образом, сократим число оцениваемых коэффициентов до двух.
<<results = 'asis'>>=
model_r1_n <- midas_r(tr_gdp ~ trend + 
                      mls(tr_gdp,1:4 ,1) + 
                      mls(tr_unemp, 0:5,3, nealmon), 
                      start = list(tr_unemp = rep(0,2)))
tab2 <- xtable(summary(model_r1_n)$coefficients, 
       caption="Коэффициенты в ограниченной модели")
align(tab2) <- "XXXXX"
print(tab2,tabular.environment = "tabularx", 
      width = "\\textwidth")
@

Конечно, теперь гораздо сложнее интерпретировать значения полученных коэффициентов, так как мы видим просто параметры функции, которая и задает веса лагам высокочастотного ряда. Аналогично можно получить модель, используя в качестве ограничений Бета функцию \eqref{Beta}. В пакете \texttt{midasr} такое ограничение получило название \texttt{nbeta}.

<<>>=
model_r1_b <- midas_r(tr_gdp ~ trend + 
                      mls(tr_gdp,1:4 ,1) + 
                      mls(tr_unemp, 0:5,3, nbeta), 
                      start = list(tr_unemp = c(0,1,0)))
@

Заметим также, что ограничение можно накладывать не только на высокочастотную переменную, но и на лаги низкочастотной. Так, мы включили в модель 4 предыдущих значения ВВП и, введя ограничение, можем оценивать 2 коэффициента вместо 4.

<<>>=
model_r2_n <- midas_r(tr_gdp ~ trend + 
                      mls(tr_gdp,1:4 ,1, nealmon) + 
                      mls(tr_unemp, 0:5,3, nealmon), 
                      start = list(tr_unemp = rep(0,2),
                                   tr_gdp = rep(0,2)))
model_r2_b <- midas_r(tr_gdp ~ trend + 
                      mls(tr_gdp,1:4 ,1, nbeta) + 
                      mls(tr_unemp, 0:5,3, nbeta), 
                      start = list(tr_unemp = rep(0,3),
                                   tr_gdp = rep(0,3)))
@

Итак, мы уже оценили 4 модели и это далеко не предел. Для того, чтобы получить качественный прогноз, нам надо ответить на два вопроса относительно нашей модели:
\begin{enumerate}
\item Какие функции ограничении лучше всего подходят для оценки параметров модели
\item Каково оптимальное число лагов для каждой переменной
\end{enumerate}

Чтобы ответить на первый вопрос, можно провести тесты на адекватность ограничений. В них проверяется нулевая гипотеза о том, что значения функции ограничений для каждого лага совпадают с истинными коэффициентами перед ними.

\begin{equation}
H_0: f_{\theta} = \beta \nonumber
\end{equation}

В \texttt{R} тест на адекватность ограничений легко реализуется с помощью команд $\texttt{hah\_test()}$ и $\texttt{hahr\_test()}$ (во втором случае используются устойчивые к гетероскедастичности и автокорреляции стандартные ошибки). Для любой модели мы получаем значение тестовой статистики, количество степеней свободы и главное --- P-Value.

<<>>=
hAhr_test(model_r1_b)
hAhr_test(model_r1_n)
@
Тест показал, что ограничения вида \texttt{nealmon} наиболее близки к истинными коэффициентам. Мы можем увидеть это, изобразив на графике коэффициенты ограниченной и неограниченной моделей.
<<>>=
plot_midas_coef(model_r1_n, 
title = "Рисунок 4. Коэффициенты с ограничениями и без")
@

На Рисунке 4 видно, что оцененная функция ограничений (синяя линия) достаточно похожа на коэффициенты в неограниченной модели (черные точки) и не выходит за их 95-\% доверительный интервал, что свидедельствует о том, что функция экспоненциальный лаг Алмон достаточно хорошо подходит для лагов безработицы. 

Допустим, мы определились с тем, что оптимальным ограничением для коэффициентов нашей модели является функция \texttt{nealmon}. Теперь надо понять, какое количество лагов надо включить в модель. Для этого в пакете есть функция \texttt{hf\_lags\_table()}, в которой можно указать номер первого (минимального) лага ---параметр \texttt{from}, а также количество лагов, из которого стоит выбирать --- \texttt{to}. 

<<results = 'hide'>>=

nlag <- hf_lags_table(tr_gdp ~ trend + 
                      mls(tr_gdp,1:2 ,1) + 
                      fmls(tr_unemp, 0, 3, nealmon), 
              start = list(tr_unemp = rep(0,3)),
              from = list(tr_unemp = 0),
              to = list(tr_unemp = c(3,11)))

@
Теперь мы можем посмотреть, какая модель лучше, сравнив их по Байесовскому информационному критерию (BIC) или критерию Акаике (AIC), как между собой, так и с неограниченными моделями. Напомним, что чем меньше значение информационного критерия, тем лучше выбранная модель. А считаются они по следующим формулам:

\begin{align}
BIC =  &-2 ln(L) + k ln(n) \nonumber \\
AIC = &-2 ln(L) + 2 k \nonumber
\end{align}

$L$ - функция правдоподобия, $k$ - количество оцениваемых коэффициентов в модели.
<<>>=
tab3 <- xtable(nlag$table[1], 
               caption="Список оцененных моделей")
tab4 <- xtable(nlag$table[2:6], 
               caption="Свойства оцененных моделей")
digits(tab4) <- matrix(rep(4,54), nrow = 9, ncol = 6)
@

<<results = 'asis'>>=
align(tab3) <- "cX"
print(tab3,tabular.environment = "tabularx", 
      width = "\\textwidth")
print(tab4, scalebox = 0.9)
@

Полученные результаты показывают, что самая лучшая модель (по обоим информационным критериям) --- ограниченная модель с 8 лагами (0:7). Причем ограниченные модели во всех случаях лучше неограниченных. Помимо значений информационного критерия, мы можем видеть P-Value для теста на адекватность ограничений. Можно заметить, что оно убывает с увеличением количества лагов, но тем не менее для 5-ой модели (лучшей по информационному критерию) гипотеза не отвергается.

Но если мы не хотим отдельно выбирать функцию ограничений и количество лагов, то можно предоставить этот выбор R. Для начала надо создать таблицу, в которой будут все варианты ограничений, лагов и необходимые начальные условия.Сделать это можно при помощи функции \texttt{expand\_weights\_lags()}.
<<>>=
unemp_set <- expand_weights_lags(
                          weights = c("nealmon", "nbeta"), 
                          from = 0, to = c(3, 11), m = 1, 
                          start = list(nealmon = rep(0,3), 
                                        nbeta = rep(0,4)))
@

Далее, используя функцию \texttt{midas\_r\_ic\_table()}, мы оцениваем все варианты моделей, которых в нашем случае $10\times 2 =20$, и получаем таблицу со всеми формулами, значениями информационных критериев и P-Value для проверки гипотезы об адекватности ограничений. Стоит заметить, что здесь уже не требуется указывать число лагов и тип ограничений внутри \texttt{mls()}, так как любая  информация будет заменена данными из таблицы \texttt{unemp\_set}, полученной выше.

<<results = 'hide'>>=
models_ic <- midas_r_ic_table(tr_gdp ~ trend + 
                                mls(tr_gdp, 1:2, m = 1) + 
                                mls(tr_unemp, 0, m = 3), 
                              table = list(tr_unemp = unemp_set))
@

Так как выбирать вручную из 20 моделей не интересно, более того, моделей может быть гораздо больше, можно воспользоваться функцией \texttt{modsel()}, которая выбирает модель по нужному критерию и показывает всю информацию о ней. Параметр \texttt{print} отвечает за то, нужно ли выводить всю информацию о выбранной модели на экран сразу.

<<>>=
choice <- modsel(models_ic, IC = "AIC", print = FALSE, 
       type = c('restricted', 'unrestricted'))
choice_info <- summary(choice)
@

Теперь мы можем посмотреть, какая именная модель была признана наиболее оптимальной по критерию Акаике.

<<>>=
choice_info$formula
@

<<results = "asis">>=
tab5 <- xtable(choice_info$coefficients, 
               caption="Коэффициенты выбранной модели")
align(tab5) <- "XXXXX"
print(tab5,tabular.environment = "tabularx", 
      width = "\\textwidth")
@

Мы получили тот же самый результат --- лучшей моделью для зависимости ВВП и безработицы по критерию Акаике является ограниченная модель (функция ограничений \texttt{nealmon}) с 8 лагами безработицы.

%%%%%%%%%%%%%%%%%%%% ПРОГНОЗ %%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Прогноз и сравнение моделей}

Итак, сравнив различные варианты спецификаций модели, мы получили оптимальную модель для зависимости ВВП и безработицы:
\begin{equation}
\label{model_opt}
GDP_t = 36.02 + 0.24 t + 1.03 GDP_{t-1} - 0.31 GDP_{t-2} +\sum_{j=0}^{7}\beta_j unemp_{3t-j}
\end{equation}

Значит, если мы хотим получить прогноз на 1 период вперед, то есть $\widehat{GDP}_{T+1|T}$, нам необходимо знать значение ВВП двух предыдущих кварталов, а также следующие значения безработицы: $unemp_{3T+3}, unemp_{3T+2}, \dots, unemp_{3T-4}$.

Функция \texttt{forecast()} предполагает, что модель, для которой мы считаем прогноз, была оценена по данным известным вплоть до момента $T$, а все, что известно после этого момента, находится в параметре \texttt{newdata}. Далее, на основании всех доступных данных строится прогноз.

Возьмем новые данные по безработице и спрогнозирует следующее значение ВВП. 
<<>>=
unemp_new <- unemp_full %>% 
             tail(-which(unemp[,1] == "dec 2013")) %>%
             head(3)
model_opt <- midas_r(tr_gdp ~ trend + 
                       mls(tr_gdp, 1:2, m = 1) + 
                       mls(tr_unemp, 0:7, m = 3, nealmon),
                     start = list(tr_unemp = rep(0,2)))
forecast(model_opt, 
         newdata = list(trend = length(trend)+1, 
                        tr_unemp = unemp_new))
@

Может быть такое, что для построения прогноза не требуются новые данные. Это происходит в том случае, если часть высокочастотных лагов не участвовала в оценке коэффициентов. То есть достаточно сдвинуть лаги безработицы в модели \eqref{model_opt} на 1 низкочастотный или 3 высокочастотных периода, и мы может получить прогноз на 1 квартал, указав в \texttt{newdata}  только следующее значение тренда.

\begin{equation}
GDP_t = \gamma_1 + \gamma_2 t + \alpha_1 GDP_{t-1} + \alpha_2 GDP_{t-2} +\sum_{j=3+0}^{3+7}\beta_j unemp_{3t-j}
\end{equation}
<<>>=
model_opt1 <- midas_r(tr_gdp ~ trend + 
                        mls(tr_gdp, 1:2, m = 1) + 
                        mls(tr_unemp, 3+0:7, m = 3, nealmon),
                      start = list(tr_unemp = rep(0,2)))
forecast(model_opt1, 
         newdata = list(trend = length(trend)+1, 
                        tr_unemp = rep(NA, 3)))
@

Пакет \texttt{midasr} предоставляет также возможность получить прогнозы сразу по нескольким моделям, а затем сравнить их по прогнозной силе на тестовой выборке. Для таких целей можно использовать функцию \texttt{select\_and\_forecast()}. В общем случае она осуществляет выбор лучшей модели для каждого горизонта прогноза среди определенного количества моделей с различными ограничениями и лагами. Однако, ее можно использовать и для того, чтобы просто получить качество прогноза для конкретной модели.

В целом, процесс выбора лучшей модели для каждого горизонта прогноза происходит аналогично тому, как это было описано выше. Однако, нам необходимо специфицировать набор моделей для каждого горизонта \texttt{h = 0, 1, 2,...}. Главное отличие появляется в лагах высокочастотных рядов. Минимальный порядок лага, включенного в модель с горизонтом 1, должен быть равен m, а с горизонтом 2 --- 2m, и так далее. За минимальное значение лагов отвечает опция \texttt{from}, которая представляет собой список векторов для каждой высокочастотной переменной. Помимо этого необходимо указать разброс лагов. За это отвечает параметр \texttt{to}, который представляет собой матрицу с минимальным и максимальным номером последнего включаемого в модель лага для каждого горизонта $h$. 

Например, если в нашей модели с ВВП и безработицей мы хотим получить прогноз на 1, 2 и 3 периода вперед. Тогда минимальные лаги, включенные в модель должны иметь номера \texttt{(3,6,9)}.  Далее, допустим, что мы предполагаем включение от 6 до 12 лагов, тогда мы должны указать следующие верхние границы: \texttt{(8,14), (11,17), (14, 20)}.

Помимо этого надо указать какая часть выборки является тренирововной, а какая --- тестовой. За это отвечают параметры \texttt{insample} И \texttt{outsample}. 

Также данная функция предоставляет возможность получать не только прогнозы отдельно по каждой модели, но и взвешанный прогноз по всем моделям для каждого значения горизонта прогноза. В статье Ghysels (2013) была описано 4 основных способа взвешивания прогнозов, каждый из которых представлен в функции \texttt{select\_and\_forecast}. Взвешанный прогноз получется следующим образом:

\begin{equation}
\label{weighted}
Y^{F}_{T+h|T} = \sum_{i=1}^n \omega_{i,T}\cdot \widehat{Y}_{i, T+h|T} 
\end{equation}

Веса прогнозов для \eqref{weighted} могут определяться следующим образом:
\begin{itemize}

\item EW --- equally weighted 
\begin{equation}
\omega_{i,t} = \frac{1}{n} \nonumber
\end{equation}

\item BICW --- взвешивание на основании критерия BIC.
\begin{equation}
\omega_{i,t} = \dfrac{exp(-BIC_i)}{\sum_j exp(-BIC_j)} \nonumber
\end{equation}

\item MSFE (DMSFE) - взвешивание на основании суммы квадратов ошибок проноза.
\begin{align}
\omega_{i,t} =& \dfrac{m^{-1}_{i,t}}{\sum_j m^{-1}_{j,t}} \nonumber\\
m_{i,t} =& \sum_{i=T_0}^{T} \delta^{T-i}(Y_{s+h}-\widehat{Y}_{i, s+h|s})^2 \nonumber\\
\delta =&
\begin{cases}
1, MSFE\\
0.9, DNSFE
\end{cases} \nonumber
\end{align}
\end{itemize}

 Исследования показывают, что использование взвешанных прогнозов улучшает их качество. Однако, нет единого мнения на счет того, какой именно способ взвешивания является оптимальным.

<<results = 'hide'>>=
trend_full <- 1:82
forecasts <- select_and_forecast(
  gdp_full ~ trend_full + mls(gdp_full, 1:2, 1) + 
                        mls(unemp_full, 0, 3), 
  from = list(unemp_full = c(3, 6, 9)), 
  to= list(unemp_full = rbind(c(8,14), c(11,17), c(14,20))), 
  insample = 1:73, outsample = 74:82, 
  weights = list(unemp_full = c("nealmon", "nbeta")), 
  wstart = list(nealmon = rep(0, 2), nbeta = rep(0, 3)), 
  IC = "AIC", 
  measures = c("MSE", "MAPE", "MASE"), 
  fweights = c("EW", "BICW", "MSFE", "DMSFE"),
  ftype = 'recursive')
@

В \texttt{forecasts} сейчас хранится информация по лучшим моделям для каждого горизонта прогноза и по каждому ограничению, то есть по 6 моделям. Мы можем посмотреть на качество прогноза по каждой из них.
<<results = 'asis'>>=
tab6 <- xtable(forecasts$accuracy$individual[1], 
       caption="Список выбранных моделей")
align(tab6) <- "cX"
print(tab6,tabular.environment = "tabularx", 
      width = "\\textwidth")
tab7 <- xtable(forecasts$accuracy$individual[, 2:4], 
       caption="Качество прогноза в выбранных моделях")
align(tab7) <- "cXXX"
print(tab7,tabular.environment = "tabularx", 
      width = "\\textwidth")
@
 Можно увидеть, что разброс значений не велик. То есть модели не сильно отличаются по качеству прогноза. Тем не менее, минимальные ошибки по всем трем показателям у моделей 3 и 5.
 
Помимио этого, можно сравнить результаты отдельных моделей с результатами взвешанного прогноза. Так как у нас было 6 моделей с тремя различными горизонтами, каждый взвешанный прогноз будет состоять из двух моделей (с одинаковым горизонтом). В параметрах функции \texttt{select\_and\_forecast} мы указали все 4 способа взвешивания, значит таблица бцдет состоять из характеристик двенадцати различных прогнозов. 
<<results = 'asis'>>=
tab8 <- xtable(forecasts$accuracy$average, 
       caption="Качество взвешанных прогнозов")
align(tab8) <- "cXXXXX"
print(tab8,tabular.environment = "tabularx", 
      width = "\\textwidth")
@

Если же у нас нет необхожимости сравнивать и выбирать из большого числа моделей, можно получить похожий результат, воспользовавшишь функцией \texttt{average\_forecast()}. С помощью нее можно получить прогнозы по одной или нескольким моделям, взвешанные прогнозы по всем выбранным моделям, а также их качество. 
<<>>=
newmod1 <- midas_r(gdp_full ~ trend_full  + 
                        mls(gdp_full, 1:2, m = 1) + 
                        mls(unemp_full, 3:8, m = 3, nealmon),
                      start = list(unemp_full = rep(0,2)))
newmod2 <- midas_r(gdp_full ~ trend_full  + 
                        mls(gdp_full, 1:2, m = 1) + 
                        mls(unemp_full, 3:15, m = 3, nbeta),
                      start = list(unemp_full = rep(0,3)))

@

<<>>=
avf <- average_forecast(
                 list(newmod1, newmod2), 
                 data = list(trend_full = trend_full, 
                             gdp_full = gdp_full, 
                             unemp_full = unemp_full),
                 insample = 1:73, outsample = 74:82,
                 type = "recursive", 
                 measures = c("MSE", "MAPE", "MASE"),
                 fweights = c("EW", "BICW", "MSFE", "DMSFE"),
                 show_progress = FALSE)
@

<<results = 'asis'>>=
tab9 <- xtable(avf$accuracy$individual[, 2:4], 
       caption="Качество прогноза всех моделей")
align(tab9) <- "cXXX"
print(tab9,tabular.environment = "tabularx", 
      width = "\\textwidth")

@
В данном случае нельзя однозначно сказать, какая из двух моделей лучше прогннозирует. Как мы видим, средняя квадратичная ошибка (MSE) и средняя абсолютная масштабированная ошибка (MASE) показывают противоположные результаты. В то же время средняя абсолютная процентная ошибка (MAPE) у обоих прогнозов одинаковая. 

Если же не выбирать из двух, а использовать взвешанный прогноз по обеим моделям, мы получим следующие результаты:
<<results = 'asis'>>=
tab10 <- xtable(avf$accuracy$average,
       caption="Качество взвешанного прогноза")
align(tab10) <- "cXXXX"
print(tab10, tabular.environment = "tabularx", 
       width = "\\textwidth")
@

\newpage
\section{Прогнозирование Российских макроэкономических данных}
\subsection{Данные}
 Для применения описанных выше моделей были выбраны следующие квартальные переменные:
\begin{itemize}

\item \textbf{gdp} --- индекс реального ВВП, \% (1 квартал 1995 года --- 100\%)

\item \textbf{inv} --- индекс рельных инвестиций в основной капитал, \% (1 квартал 1993 года --- 100\%)
\end{itemize}
 
Следующие высокочастотные переменные, с ежемесячными наблюдениями, были выбраны объясняющими.
\begin{itemize}

\item \textbf{unemp} --- беработица, \%

\item \textbf{cpi} --- индекс потребительский цен, в \% к предыдущему году

\item \textbf{bci} --- business confidence index, рассчитывается ОЭСР на основании текущих состояний компаний и прогнозов относительно ближайшего будущего, 100 соответствует среднему по всем странам значению

\item \textbf{oil} --- цена нефти марки Brent, \$
\end{itemize}
 
В модели включалось 3 лага низкочастотно переменной, и от 6 до 9 лагов высокочастотных.В тренировочную выборку по квартальным переменным бли включены данные вплоть до 4 квартала 2014 года, в тестовую - первые 3 квартала 2015 года. Что касается высокочастотных данных, их тестовая выборка имеет три различные конфигурации: данные до февраля 2015, до марта 2015 и до апреля 2015. Это связано с различной частотой публикации данных в реальной жизни. Квартальные данные последнего периода года становятся доступны только в апреле следующего года, к этому моменту месячные показатели доступны вплоть до февраля. Следущие квартальные данные (за 1 квартал текущего года) будут опубликованы только в июле. Тем не менее в мае и июне доступные месячные показатели будут обновляться. Отсюда можно сделать два вывода:
\begin{itemize}

\item Есть необходимость пронозировать не только будущие значение квартальных данных, но и показатель предыдущего и текущего квартала, так как пукликация происходит с задержкой
\item Состав данных, которыми располагает исследователь зависит от того, в каком месяце квартала он находится
\end{itemize}

\subsection{Методы прогнозирования}
Для сравнения были выбраны прогнозы по 8 различным моделям. Для каждого класса моделей была выбрана спецификация с минимальным MSE (mean squred error) для тренировочной выборки. Далее - посчитано значение MSE для тестовой выборки. В разделе результаты для каждой зависимой переменной представлены результаты 5 лучших моделей в зависимости от того, в каком месяце квартала производился прогноз. Рассмотрим подробнее выбранные модели.

Для прогнозирования ВВП и инвестиций было использовано 4 различных спецификации \textbf{MIDAS}:
\begin{itemize}
\item \textbf{N}(Nealmon) --- ограничения вида экспоненциальный лаг Алмон \eqref{Almon}  для всех высокочастотных переменных, модель с минимальным MSE на тренировочной выборке
\item \textbf{NW}(Nealmon weighted) --- средневзвешанный (EW) прогноз по всем моделям Nealmon
\item \textbf{B}(Beta) --- ограничения вида Бета \eqref{Beta} для всех высокочастотных переменных, модель с минимальным MSE на тренировочной выборке
\item \textbf{BW}(Beta weighted) --- средневзвешанный (EW) прогноз по всем моделям с ограничением Бета функции
\end{itemize}

Для сравнения, были также оценены 4 более простые модели:

\begin{itemize}
\item \textbf{SW}(Step Weightning) --- неограниченная модель \eqref{unrestricted_main}, модель с минимальным MSE на тренировочной выборке
\item \textbf{TA}(Time Averaging) --- агрегирование данных с помощью среднего арифметического \eqref{time_av}, модель с минимальным MSE на тренировочной выборке
\item \textbf{ARIMA} --- авторегресионная модель со скользящим средним
\item \textbf{AR} --- авторегрегресионная модель
\end{itemize}
В двух последних случаях результат не зависит от номера месяца, так как высокочастотне данные не включены в модель, то есть доступная информация не изменяется внутри одного квартала.

\newpage
\subsection{Результаты}

В таблицах ниже представлены результаты, полученные при прогнозировании квартальных инвестиций и ВВП с использованием их лагов, а также лагов таких высокочастотных переменных как уровень цен, индекс деловой уверенности, цена нефти и уровень безработицы. В таблице \ref{inv} содержатся пять моделей с минимальной среднеквадратичной ошибкой при прогнозировании инвестиций для каждого из трех месяцев квартала.
\begin{table}[h]
\Large
\renewcommand{\arraystretch}{1.5}
\centering
\begin{tabularx}{\textwidth}{cXXX}
  \hline
 & Месяц 1 & Месяц 2  & Месяц 3 \\ 
  \hline
 \parbox[t]{20mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{MSE}}} & $ \underset{NW}{56.856}$ & $\underset{BW}{22.121} $ &  $\underset{N}{54.805}  $\\ 
 &  $\underset{N}{65.573} $   & $\underset{B}{22.854}  $   &$ \underset{NW}{70.483}$\\
 &  $\underset{AR}{129.746} $ &  $\underset{NW}{64.767}$   & $ \underset{AR}{129.746}$ \\
 &  $\underset{TA}{202.566}$   & $\underset{N}{66.38} $  &  $\underset{TA}{204.556} $\\
 &  $\underset{BW}{509.851}$ & $\underset{AR}{129.746} $   & $\underset{B}{218.849} $\\
   \hline
\end{tabularx}
\caption{Качество прогноза, инвестиции}
\label{inv}
\end{table}

Мы можем видеть, что во всех трех случаях  MIDAS модели показали наилучий результат. Из 12 выбанных для сравнения моделей, в таблицу вошли 10. Причем почти всегда взвешанный прогноз по всем моделям оказался лучше прогноза одной, выбранной по тестовой выборке, модели. Помимо моделей MIDAS в список лучших вошла простая авторегрессия и модель со средневзвешанными по времени высокочастотными данными.

Второй переменной, для которой был построен прогноз является ВВП. Результаты мы можем наблюдать в таблице \ref{gdp}. 
\begin{table}[h]
\Large
\renewcommand{\arraystretch}{1.5}
\centering
\begin{tabularx}{\textwidth}{cXXX}
  \hline 
 & Месяц 1 & Месяц 2  & Месяц 3 \\ 
  \hline
\parbox[t]{20mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{MSE}}} & $\underset{AR}{2.883}$  & $\underset{AR}{2.883}$  & $\underset{AR}{2.883}$  \\      
&   $\underset{NW}{4.972}$ & $ \underset{N}{4.778}$    & $\underset{N}{3.587} $   \\     
 & $ \underset{N}{ 6.4418}  $ & $\underset{NW}{4.806} $  &  $\underset{NW}{3.971}$   \\   
 & $\underset{ARIMA}{21.589} $& $\underset{ARIMA}{21.5895}$ & $\underset{BW}{20.734}$  \\
 &$   \underset{BW}{21.635}$ & $\underset{BW}{22.121}  $    & $\underset{ARIMA}{21.589}$ \\  
   \hline
\end{tabularx}
\caption{Качество прогноза, ВВП}
\label{gdp}
\end{table}


 В этом случае высокие результаты показали авторегрессионные модели: AR и ARIMA вошли в число лучших для каждого месяца. Тем не менее, MIDAS модели показали достаточно высокие результаты, так как в каждом из месяцев 3 из 4 вошли в списоклучших по среднеквадратичной ошибке. 
 
Все расчеты можно найти в \href{https://github.com/AKuzina/MIDAS}{репозитории} на GitHub.

\newpage
\section{Выводы}
Модели MIDAS предоставляют широкие возможности для построения моделей с данными разной частоты. В данной работы был описан принцип работы таких моделей, который заключается в том, что на коэффициенты перед лагами высокочастотных переменных накладывается определенное функциональное ограничение. Гибкость данных функций способствует тому, что качество прогнозов не страдает, в то время как количество параметров, которые необходимо оценить, снижается 

Для применения моделей к реальным данным крайне удобно использовать пакет \texttt{midasr}. В работе были описаны его основные функции, с помощью которых можно оценивать модели, выбирать виды ограничений и количество лагов. Также он обладает широким набором инструментов для прогнозирования моделей с данными разной частоты и оценки качества полученных прогнозов.

Для сравнения моделей MIDAS c такими моделями как ARIMA, AR, Time Averaging и Step Weightning, были оценены модели для инвестиций и ВВП в зависимости от безработицы, цен на нефть, курса доллара и индекса деловой уверенности. MIDAS модели показали высокие результаты, однако, нельзя однозначно утверждать, что они являются лучшим инструментом в данной сфере. 


\newpage
\section{Приложения}
\subsection*{Приложение 1а. Построение графика функции экпоненциальный лаг Алмон}
<<fig.keep='none'>>=
lags_exp <- seq(1,252, 1)
len_exp <- length(lags_exp)
exp_func <- function(k, theta_1, theta_2){
  f = exp(theta_1*k+theta_2*(k^2))
  return(f)
}
restriction_exp <- function(k, theta_1, theta_2){
  inter = 0
  for (i in 1:len_exp){
    inter = inter + exp_func(lags_exp[i], theta_1, theta_2)
  }
  return(exp_func(k, theta_1, theta_2)/inter)
}
weights_exp <- data.frame(lags_exp = lags_exp, 
                          weight_1 = rep(NA, len_exp),
                          weight_2 = rep(NA, len_exp),
                          weight_3 = rep(NA, len_exp),
                          weight_4 = rep(NA, len_exp))
for (i in 1:len_exp){
  weights_exp[i,2] <- 
    restriction_exp(lags_exp[i], 0.0007,-0.0004)
  weights_exp[i,3] <- 
    restriction_exp(lags_exp[i], 0.006,-0.0008)
  weights_exp[i,4] <- 
    restriction_exp(lags_exp[i], 0.03,-0.0007)
  weights_exp[i,5] <- 
    restriction_exp(lags_exp[i], 0.0001,-0.0001)
}
weight_long_exp <- melt(weights_exp, 
                        value.name = "weight", 
                        measure.vars = c("weight_1",
                                         "weight_2",
                                         "weight_3",
                                         "weight_4"))
qplot(data = weight_long_exp, x = lags_exp, 
      y = weight,color = variable, geom = "line") + 
  theme(legend.position = c(0.86, 0.74), 
        legend.key.size = unit(1.5,"cm"),
        text = element_text(size = 14))+
  labs(list(title = "Рисунок 1. Экспоненциальный лаг", 
            x = "Лаги", y = "Веса наблюдений "))+
  scale_colour_discrete(name="",
                        breaks=c("weight_1", "weight_2", 
                                 "weight_3","weight_4"),
                        labels=c("0.0007,-0.0004",
                                 "0.006,-0.0008",
                                 "0.03,-0.0007", 
                                 "0.0001,-0.0001"))
@


\subsection*{Приложение 1b. Построение графика Бета функции}

<<fig.keep='none'>>=
lags <- seq(1,84, 1)
len <- length(lags)
beta_func <- function(k, theta_1, theta_2){
  a = k/len
  f = (a^(theta_1-1)*(1-a)^(theta_2-1))/beta(theta_1, theta_2)
  return(f)
}
restriction <- function(k, theta_1, theta_2){
  inter = 0
  for (i in 1:len){
    inter = inter + beta_func(lags[i], theta_1, theta_2)
  }
  return(beta_func(k, theta_1, theta_2)/inter)
}
weights <- data.frame(lags = lags, weight_1 = rep(NA, len),
                      weight_2 = rep(NA, len),
                      weight_3 = rep(NA, len),
                      weight_4 = rep(NA, len))
for (i in 1:len){
  weights[i,2] <- restriction(lags[i], 1,30)
  weights[i,3] <- restriction(lags[i], 4,9)
  weights[i,4] <- restriction(lags[i], 1.5,3)
  weights[i,5] <- restriction(lags[i], 2,18)
}
weight_long <- melt(weights, value.name = "weight", 
                    measure.vars = c("weight_1",
                                     "weight_2",
                                     "weight_3",
                                     "weight_4"))
qplot(data = weight_long, x = lags, 
      y = weight,color = variable, geom = "line") + 
  theme(legend.position = c(0.91, 0.74), 
        legend.key.size = unit(1.5,"cm"),
        text = element_text(size = 14))+
  labs(list(title = "Рисунок 2. Бета-функция", 
            x = "Лаги", y = "Веса наблюдений "))+
  scale_colour_discrete(name="",
                        breaks=c("weight_1", "weight_2", 
                                 "weight_3","weight_4"),
                        labels=c("1; 30","4; 9",
                                 "1.5; 3", "2; 18"))+
  ylim(0,0.15)
@


\newpage
\begin{thebibliography}{99}

\bibitem{Armesto}
Armesto M. T., Engemann K. M., Owyang M. T. Forecasting with mixed frequencies //Review. – 2010. – Т. 92.

\bibitem{Clements}
Clements M. P., Galvão A. B. Forecasting US output growth using leading indicators: An appraisal using MIDAS models //Journal of Applied Econometrics. – 2009. – Т. 24. – №. 7. – С. 1187-1206.

\bibitem{ghysels04}
Ghysels E., Santa-Clara P., Valkanov R. The MIDAS touch: Mixed data sampling regression models //Finance. – 2004.

\bibitem{Ghysels05}
Ghysels E., Santa-Clara P., Valkanov R. There is a risk-return trade-off after all //Journal of Financial Economics. – 2005. – Т. 76. – №. 3. – С. 509-548.

\bibitem{Ghysels06}
Ghysels G., Valkanov R. Linear time series processes with mixed data sampling and MIDAS regression models //Social science research network. – 2006.

\bibitem{Ghysels07}
Ghysels E., Sinko A., Valkanov R. MIDAS regressions: Further results and new directions //Econometric Reviews. – 2007. – Т. 26. – №. 1. – С. 53-90.

\bibitem{Ghysels13}
Ghysels E. Matlab Toolbox for Mixed Sampling Frequency Data Analysis using MIDAS Regression Models //Unpublished Manuscript. – 2013.

\bibitem{Kuzin}
Kuzin V., Marcellino M., Schumacher C. MIDAS vs. mixed-frequency VAR: Nowcasting GDP in the euro area //International Journal of Forecasting. – 2011. – Т. 27. – №. 2. – С. 529-542.


\end{thebibliography} 
\end{document}